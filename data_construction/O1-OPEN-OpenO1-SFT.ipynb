{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "from utils import get_response_openai_prompt\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import secrets\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_strings(count, length):\n",
    "    unique_strings = set()\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    while len(unique_strings) < count:\n",
    "        random_string = \"\".join(secrets.choice(characters) for _ in range(length))\n",
    "        unique_strings.add(random_string)\n",
    "    return list(unique_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file):\n",
    "    with open(config_file, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), \"..\", \"config.yaml\")\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "hf_token = config[\"huggingface\"][\"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"O1-OPEN/OpenO1-SFT\", token=hf_token)\n",
    "df = Dataset.to_pandas(ds[\"train\"])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(1000, random_state=3407)\n",
    "df = df[500:1000]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = generate_unique_strings(len(df), 10)\n",
    "print(f\"Generated {len(ids)} Unique IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(columns=[\"prompt\", \"response_a\", \"response_b\", \"model_a\", \"model_b\", \"winner\", \"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_system = \"You are a great translator. You need to provide the most accurate and high-quality translations possible.\"\n",
    "russian_system1 = \"Вам нужно серьезно отвечать на вопросы пользователей, предоставляя точные и качественные ответы в пределах ваших возможностей.\"\n",
    "russian_system2 = \"Вам нужно поверхностно отвечать на вопросы пользователя, предоставляя неточные и низкокачественные ответы.\"\n",
    "chinese_system1 = \"你需要认真地回复用户的问题，力所能及地提供精确，高质量的回答。\"\n",
    "chinese_system2 = \"你需要很敷衍地回答用户的问题，给出不精确的，低质量的答复。\"\n",
    "vitnamese_system1 = \"Bạn cần trả lời các câu hỏi của người dùng một cách nghiêm túc, cung cấp câu trả lời chính xác và chất lượng cao trong khả năng của mình.\"\n",
    "vitnamese_system2 = \"Bạn cần trả lời câu hỏi của người dùng một cách hời hợt, đưa ra các câu trả lời không chính xác và chất lượng thấp.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    if idx < len(df) // 3:\n",
    "        instruction = row[\"instruction\"]\n",
    "\n",
    "        translated_instruction = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=translation_system,\n",
    "            prompt=f\"Translate the following instruction to Russian: {instruction}.\\nYou should only return the translation.\"\n",
    "        )\n",
    "        if translated_instruction is None:\n",
    "            continue\n",
    "\n",
    "        chosen_response = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=russian_system1,\n",
    "            prompt=translated_instruction,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        if chosen_response is None:\n",
    "            continue\n",
    "\n",
    "        rejected_response = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=russian_system2,\n",
    "            prompt=translated_instruction,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        if rejected_response is None:\n",
    "            continue\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"prompt\": translated_instruction,\n",
    "                \"response_a\": chosen_response,\n",
    "                \"response_b\": rejected_response,\n",
    "                \"model_a\": model,\n",
    "                \"model_b\": model,\n",
    "                \"winner\": \"model_a\",\n",
    "                \"language\": \"Russian\"\n",
    "            }])\n",
    "        else:\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"prompt\": translated_instruction,\n",
    "                \"response_a\": rejected_response,\n",
    "                \"response_b\": chosen_response,\n",
    "                \"model_a\": model,\n",
    "                \"model_b\": model,\n",
    "                \"winner\": \"model_b\",\n",
    "                \"language\": \"Russian\"\n",
    "            }])\n",
    "\n",
    "        new_data = pd.concat([new_data, new_row], ignore_index=True)\n",
    "\n",
    "    elif idx < 2 * len(df) // 3:\n",
    "        instruction = row[\"instruction\"]\n",
    "\n",
    "        translated_instruction = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=translation_system,\n",
    "            prompt=f\"Translate the following instruction to Chinese: {instruction}.\\nYou should only return the translation.\"\n",
    "        )\n",
    "        if translated_instruction is None:\n",
    "            continue\n",
    "\n",
    "        chosen_response = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=chinese_system1,\n",
    "            prompt=translated_instruction,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        if chosen_response is None:\n",
    "            continue\n",
    "\n",
    "        rejected_response = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=chinese_system2,\n",
    "            prompt=translated_instruction,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        if rejected_response is None:\n",
    "            continue\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"prompt\": translated_instruction,\n",
    "                \"response_a\": chosen_response,\n",
    "                \"response_b\": rejected_response,\n",
    "                \"model_a\": model,\n",
    "                \"model_b\": model,\n",
    "                \"winner\": \"model_a\",\n",
    "                \"language\": \"Chinese\"\n",
    "            }])\n",
    "        else:\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"prompt\": translated_instruction,\n",
    "                \"response_a\": rejected_response,\n",
    "                \"response_b\": chosen_response,\n",
    "                \"model_a\": model,\n",
    "                \"model_b\": model,\n",
    "                \"winner\": \"model_b\",\n",
    "                \"language\": \"Chinese\"\n",
    "            }])\n",
    "\n",
    "        new_data = pd.concat([new_data, new_row], ignore_index=True)\n",
    "    \n",
    "    else:\n",
    "        instruction = row[\"instruction\"]\n",
    "\n",
    "        translated_instruction = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=translation_system,\n",
    "            prompt=f\"Translate the following instruction to Vitnamese: {instruction}.\\nYou should only return the translation.\"\n",
    "        )\n",
    "        if translated_instruction is None:\n",
    "            continue\n",
    "\n",
    "        chosen_response = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=vitnamese_system1,\n",
    "            prompt=translated_instruction,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        if chosen_response is None:\n",
    "            continue\n",
    "\n",
    "        rejected_response = get_response_openai_prompt(\n",
    "            model=model,\n",
    "            system=vitnamese_system2,\n",
    "            prompt=translated_instruction,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        if rejected_response is None:\n",
    "            continue\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"prompt\": translated_instruction,\n",
    "                \"response_a\": chosen_response,\n",
    "                \"response_b\": rejected_response,\n",
    "                \"model_a\": model,\n",
    "                \"model_b\": model,\n",
    "                \"winner\": \"model_a\",\n",
    "                \"language\": \"Vitnamese\"\n",
    "            }])\n",
    "        else:\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"prompt\": translated_instruction,\n",
    "                \"response_a\": rejected_response,\n",
    "                \"response_b\": chosen_response,\n",
    "                \"model_a\": model,\n",
    "                \"model_b\": model,\n",
    "                \"winner\": \"model_b\",\n",
    "                \"language\": \"Vitnamese\"\n",
    "            }])\n",
    "\n",
    "        new_data = pd.concat([new_data, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[\"id\"] = ids\n",
    "df = new_data.copy()\n",
    "df = df[[\"id\", \"prompt\", \"response_a\", \"response_b\", \"winner\", \"model_a\", \"model_b\", \"language\"]]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"response_a\"][1], df[\"response_b\"][1]\n",
    "df.to_parquet(\"./self-generation-zh-ru-vi-2.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
