{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file):\n",
    "    with open(config_file, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), \"..\", \"config.yaml\")\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "hf_token = config[\"huggingface\"][\"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"lmarena-ai/arena-human-preference-55k\", token=hf_token)\n",
    "df = Dataset.to_pandas(ds[\"train\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39716, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"winner_tie\"] != 1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it morally right to try to have a certain percentage of females on managerial positions?\n",
      "OK, does pineapple belong on a pizza? Relax and give me fun answer.\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(df[\"prompt\"][0])[0])\n",
    "print(json.loads(df[\"prompt\"][0])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prompt\"] = df[\"prompt\"].apply(json.loads)\n",
    "df[\"response_a\"] = df[\"response_a\"].apply(json.loads)\n",
    "df[\"response_b\"] = df[\"response_b\"].apply(json.loads)\n",
    "\n",
    "df = df[df[\"prompt\"].apply(lambda x: len(x) == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>[How can I create a test set for a very rare c...</td>\n",
       "      <td>[Creating a test set for a very rare category ...</td>\n",
       "      <td>[When building a classifier for a very rare ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>[What is the best way to travel from Tel-Aviv ...</td>\n",
       "      <td>[The best way to travel from Tel Aviv to Jerus...</td>\n",
       "      <td>[The best way to travel from Tel-Aviv to Jerus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>292873</td>\n",
       "      <td>[Construct a rap battle, in the style of Epic ...</td>\n",
       "      <td>[[Zeus]\\nYo, it's the king of the gods on the ...</td>\n",
       "      <td>[(Verse 1 - Zeus)\\n\\nI'm the king of the gods,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>313413</td>\n",
       "      <td>[Why water is not used in bath tub?]</td>\n",
       "      <td>[Water is actually used in a bath tub. A bath ...</td>\n",
       "      <td>[Water is not used in a bath tub because it is...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>370945</td>\n",
       "      <td>[\"Bacteria is life on Mars but a heartbeat isn...</td>\n",
       "      <td>[Dune]</td>\n",
       "      <td>[This quote seems to be referencing the debate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>claude-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             prompt  \\\n",
       "3   96401  [How can I create a test set for a very rare c...   \n",
       "4  198779  [What is the best way to travel from Tel-Aviv ...   \n",
       "5  292873  [Construct a rap battle, in the style of Epic ...   \n",
       "6  313413               [Why water is not used in bath tub?]   \n",
       "7  370945  [\"Bacteria is life on Mars but a heartbeat isn...   \n",
       "\n",
       "                                          response_a  \\\n",
       "3  [Creating a test set for a very rare category ...   \n",
       "4  [The best way to travel from Tel Aviv to Jerus...   \n",
       "5  [[Zeus]\\nYo, it's the king of the gods on the ...   \n",
       "6  [Water is actually used in a bath tub. A bath ...   \n",
       "7                                             [Dune]   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "3  [When building a classifier for a very rare ca...               1   \n",
       "4  [The best way to travel from Tel-Aviv to Jerus...               0   \n",
       "5  [(Verse 1 - Zeus)\\n\\nI'm the king of the gods,...               0   \n",
       "6  [Water is not used in a bath tub because it is...               1   \n",
       "7  [This quote seems to be referencing the debate...               0   \n",
       "\n",
       "   winner_model_b                     model_a              model_b  \n",
       "3               0            llama-2-13b-chat  mistral-7b-instruct  \n",
       "4               1                   koala-13b   gpt-3.5-turbo-0314  \n",
       "5               1                  vicuna-13b           gpt-4-0314  \n",
       "6               0  mixtral-8x7b-instruct-v0.1           vicuna-13b  \n",
       "7               1                  gemini-pro           claude-2.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"id\", \"prompt\", \"response_a\", \"response_b\", \"winner_model_a\", \"winner_model_b\", \"model_a\", \"model_b\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34297/34297 [00:02<00:00, 12638.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34297, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>292873</td>\n",
       "      <td>Construct a rap battle, in the style of Epic R...</td>\n",
       "      <td>[Zeus]\\nYo, it's the king of the gods on the m...</td>\n",
       "      <td>(Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>313413</td>\n",
       "      <td>Why water is not used in bath tub?</td>\n",
       "      <td>Water is actually used in a bath tub. A bath t...</td>\n",
       "      <td>Water is not used in a bath tub because it is ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>370945</td>\n",
       "      <td>\"Bacteria is life on Mars but a heartbeat isn'...</td>\n",
       "      <td>Dune</td>\n",
       "      <td>This quote seems to be referencing the debate ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             prompt  \\\n",
       "3   96401  How can I create a test set for a very rare ca...   \n",
       "4  198779  What is the best way to travel from Tel-Aviv t...   \n",
       "5  292873  Construct a rap battle, in the style of Epic R...   \n",
       "6  313413                 Why water is not used in bath tub?   \n",
       "7  370945  \"Bacteria is life on Mars but a heartbeat isn'...   \n",
       "\n",
       "                                          response_a  \\\n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "5  [Zeus]\\nYo, it's the king of the gods on the m...   \n",
       "6  Water is actually used in a bath tub. A bath t...   \n",
       "7                                               Dune   \n",
       "\n",
       "                                          response_b   winner  \\\n",
       "3  When building a classifier for a very rare cat...  model_a   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...  model_b   \n",
       "5  (Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...  model_b   \n",
       "6  Water is not used in a bath tub because it is ...  model_a   \n",
       "7  This quote seems to be referencing the debate ...  model_b   \n",
       "\n",
       "                      model_a              model_b language  \n",
       "3            llama-2-13b-chat  mistral-7b-instruct  English  \n",
       "4                   koala-13b   gpt-3.5-turbo-0314  English  \n",
       "5                  vicuna-13b           gpt-4-0314  English  \n",
       "6  mixtral-8x7b-instruct-v0.1           vicuna-13b  English  \n",
       "7                  gemini-pro           claude-2.0  English  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = []\n",
    "response_as = []\n",
    "response_bs = []\n",
    "winners = []\n",
    "languages = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    prompts.append(row[\"prompt\"][0])\n",
    "    response_as.append(row[\"response_a\"][0])\n",
    "    response_bs.append(row[\"response_b\"][0])\n",
    "    if row[\"winner_model_a\"] == 1:\n",
    "        winners.append(\"model_a\")\n",
    "    elif row[\"winner_model_b\"] == 1:\n",
    "        winners.append(\"model_b\")\n",
    "    languages.append(\"English\")\n",
    "\n",
    "df[\"prompt\"] = prompts\n",
    "df[\"response_a\"] = response_as\n",
    "df[\"response_b\"] = response_bs\n",
    "df[\"winner\"] = winners\n",
    "df[\"language\"] = languages\n",
    "\n",
    "df.drop(columns=[\"winner_model_a\", \"winner_model_b\"], inplace=True)\n",
    "df = df[[\"id\", \"prompt\", \"response_a\", \"response_b\", \"winner\", \"model_a\", \"model_b\", \"language\"]]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winner\n",
       "model_a    17312\n",
       "model_b    16985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"winner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"lmarena-ai-arena-human-preference-55k.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
