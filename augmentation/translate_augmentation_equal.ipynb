{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from utils import get_response_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../original_data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"language\"].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_counts = train[\"language\"].value_counts().to_dict()\n",
    "\n",
    "with open(\"language_counts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(language_counts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmarena_ai_arena_human_preference_55k = pd.read_parquet(\"../external_data/lmarena-ai-arena-human-preference-55k.parquet\")\n",
    "print(lmarena_ai_arena_human_preference_55k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split()) if text else 0\n",
    "\n",
    "lmarena_ai_arena_human_preference_55k[\"prompt_word_count\"] = lmarena_ai_arena_human_preference_55k[\"prompt\"].apply(word_count)\n",
    "lmarena_ai_arena_human_preference_55k[\"response_a_word_count\"] = lmarena_ai_arena_human_preference_55k[\"response_a\"].apply(word_count)\n",
    "lmarena_ai_arena_human_preference_55k[\"response_b_word_count\"] = lmarena_ai_arena_human_preference_55k[\"response_b\"].apply(word_count)\n",
    "\n",
    "lmarena_ai_arena_human_preference_55k = lmarena_ai_arena_human_preference_55k[(lmarena_ai_arena_human_preference_55k[\"prompt_word_count\"] <= 512) & (lmarena_ai_arena_human_preference_55k[\"response_a_word_count\"] <= 512) & (lmarena_ai_arena_human_preference_55k[\"response_b_word_count\"] <= 512)]\n",
    "lmarena_ai_arena_human_preference_55k = lmarena_ai_arena_human_preference_55k.drop(columns=[\"prompt_word_count\", \"response_a_word_count\", \"response_b_word_count\"])\n",
    "lmarena_ai_arena_human_preference_55k = lmarena_ai_arena_human_preference_55k.dropna()\n",
    "lmarena_ai_arena_human_preference_55k.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(lmarena_ai_arena_human_preference_55k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmarena_ai_arena_human_preference_55k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = []\n",
    "\n",
    "for language, count in language_counts.items():\n",
    "    if language != \"English\" and language != \"unknown\" and language != \"xx\" and language != \"zzp\" and count < 200:\n",
    "        languages.append(language)\n",
    "\n",
    "print(len(languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmarena_ai_arena_human_preference_55k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 0\n",
    "\n",
    "def generate_integers(id):\n",
    "    start = id * os.cpu_count()\n",
    "    end = start + os.cpu_count() - 1\n",
    "    if end > len(languages):\n",
    "        end = len(languages) - 1\n",
    "    return list(range(start, end + 1))\n",
    "\n",
    "group_index = generate_integers(group_id)\n",
    "print(group_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_each_language = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_aug_lmarena_ai_arena_human_preference_55k = pd.DataFrame(columns=lmarena_ai_arena_human_preference_55k.columns)\n",
    "\n",
    "\n",
    "def translate_row(row, target_language):\n",
    "    try:\n",
    "        translated_prompt = get_response_openai(model=\"gpt-4o-mini\", prompt=f\"Translate the following text to {target_language}:\\n{row['prompt']}\\nOnly return your translation, do not include any other text.\")\n",
    "        translated_response_a = get_response_openai(model=\"gpt-4o-mini\", prompt=f\"Translate the following text to {target_language}:\\n{row['response_a']}\\nOnly return your translation, do not include any other text.\")\n",
    "        translated_response_b = get_response_openai(model=\"gpt-4o-mini\", prompt=f\"Translate the following text to {target_language}:\\n{row['response_b']}\\nOnly return your translation, do not include any other text.\")\n",
    "\n",
    "        return {\n",
    "            \"id\": row[\"id\"],\n",
    "            \"prompt\": translated_prompt,\n",
    "            \"response_a\": translated_response_a,\n",
    "            \"response_b\": translated_response_b,\n",
    "            \"winner\": row[\"winner\"],\n",
    "            \"model_a\": row[\"model_a\"],\n",
    "            \"model_b\": row[\"model_b\"],\n",
    "            \"language\": target_language\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error with row {row['id']}: {e}\")\n",
    "        return {\n",
    "            \"id\": row[\"id\"],\n",
    "            \"prompt\": row[\"prompt\"],\n",
    "            \"response_a\": row[\"response_a\"],\n",
    "            \"response_b\": row[\"response_b\"],\n",
    "            \"winner\": row[\"winner\"],\n",
    "            \"model_a\": row[\"model_a\"],\n",
    "            \"model_b\": row[\"model_b\"],\n",
    "            \"language\": row[\"language\"]\n",
    "        }\n",
    "\n",
    "\n",
    "def process_language_chunk(language_id, chunk_data):\n",
    "    target_language = languages[language_id]\n",
    "    results = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(translate_row, row, target_language) for _, row in chunk_data.iterrows()]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "for language_id in group_index:\n",
    "    lmarena_ai_arena_human_preference_55k_chunk = lmarena_ai_arena_human_preference_55k[num_each_language * language_id: num_each_language * (language_id + 1)]\n",
    "    translated_results = process_language_chunk(language_id, lmarena_ai_arena_human_preference_55k_chunk)\n",
    "    translation_aug_lmarena_ai_arena_human_preference_55k = pd.concat([translation_aug_lmarena_ai_arena_human_preference_55k, pd.DataFrame(translated_results)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_aug_lmarena_ai_arena_human_preference_55k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_aug_lmarena_ai_arena_human_preference_55k[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_aug_lmarena_ai_arena_human_preference_55k.to_csv(f\"translation_aug_equal_lmarena-ai-arena-human-preference-55k-{group_id}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
