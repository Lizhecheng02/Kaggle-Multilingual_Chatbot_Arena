train_data: './train_data_sort.parquet'
valid_data: './dev_data_sort.parquet'
resume_from_checkpoint: './all_similar_distribution_150k_for_pl_drop_dup_lmsys_pl_filter_v4_long_first_base_on_gen_model_cv_695_lb_695_drop_dup_long_first/checkpoint-16000'
per_device_train_batch_size: 2
per_device_eval_batch_size: 8
learning_rate: 6.e-5
lr_end: 1.e-9
warmup_ratio: 0.1
num_train_epochs: 1
gradient_accumulation_steps: 8
logging_steps: 10
eval_steps: 300
save_steps: 100
weight_decay: 1.e-5
MAX_INPUT: 3072
MODEL: google/gemma-2-9b-it
dropout_rate: 0.1
label_smoothing_factor: 0
output_dir: ./output/gemma_cls_advanced
lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
truncation_type: 'lzc'
test_mode: False
model_type: gemma
run_name: lzc_truncation